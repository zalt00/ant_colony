{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28ddbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac28bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mylib\n",
    "import importlib\n",
    "mylib = importlib.reload(mylib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53df73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "\n",
    "class EdgePolicy(torch.nn.Module):\n",
    "    def __init__(self, node_feat_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # MLP pour GINEConv\n",
    "        gin_nn1 = Sequential(Linear(node_feat_dim, hidden_dim),\n",
    "                             ReLU(),\n",
    "                             Linear(hidden_dim, hidden_dim))\n",
    "        gin_nn2 = Sequential(Linear(hidden_dim, hidden_dim),\n",
    "                             ReLU(),\n",
    "                             Linear(hidden_dim, hidden_dim))\n",
    "\n",
    "        self.conv1 = GINEConv(gin_nn1, edge_dim=2)\n",
    "        self.conv2 = GINEConv(gin_nn2, edge_dim=2)\n",
    "\n",
    "        # head pour scorer chaque arête\n",
    "        self.edge_mlp = Sequential(\n",
    "            Linear(2*hidden_dim + 2, hidden_dim),\n",
    "            ReLU(),\n",
    "            Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # 1. Message passing\n",
    "        h = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        h = self.conv2(h, edge_index, edge_attr)\n",
    "\n",
    "        # 2. Préparer embeddings d'arêtes\n",
    "        src, dst = edge_index\n",
    "        h_edge = torch.cat([h[src], h[dst], edge_attr], dim=-1)\n",
    "\n",
    "        # 3. Scores bruts\n",
    "        logits = self.edge_mlp(h_edge).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fb459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = mylib.Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c157aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des arêtes\n",
    "edges = helper.get_dataset()\n",
    "num_nodes = max(max(u,v) for u,v,t in edges) + 1\n",
    "\n",
    "# Séparer arrays pour plus de rapidité\n",
    "edge_index = torch.tensor([[u for u,v,t in edges],\n",
    "                           [v for u,v,t in edges]], dtype=torch.long)\n",
    "edge_types = torch.tensor([t for u,v,t in edges], dtype=torch.long)\n",
    "\n",
    "edge_to_id = {frozenset((u, v)): i for (i, (u, v, _)) in enumerate(edges)}\n",
    "\n",
    "# Node features initiales (ici, vecteurs unité)\n",
    "node_feat_dim = 1\n",
    "x_init = torch.ones((num_nodes, node_feat_dim), dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04cf64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 050 | Réward cumulé 0.24\n",
      "Épisode 100 | Réward cumulé 0.31\n",
      "Épisode 150 | Réward cumulé 0.34\n",
      "Épisode 200 | Réward cumulé 0.44\n",
      "Épisode 250 | Réward cumulé 0.50\n",
      "Épisode 300 | Réward cumulé 0.12\n",
      "Épisode 350 | Réward cumulé 0.43\n",
      "Épisode 400 | Réward cumulé 0.16\n",
      "Épisode 450 | Réward cumulé 0.35\n",
      "Épisode 500 | Réward cumulé 0.24\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "# Hyperparamètres\n",
    "hidden_dim = 64\n",
    "lr = 1e-3\n",
    "episodes = 500\n",
    "max_steps = 20 # len(edges)  # au pire on flippes toutes les arêtes\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EdgePolicy(node_feat_dim, hidden_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for ep in range(episodes):\n",
    "    # Réinitialiser l'état\n",
    "    helper.reset(ep)\n",
    "    edges = helper.get_dataset()\n",
    "    edge_index = torch.tensor([[u for u,v,t in edges],\n",
    "                           [v for u,v,t in edges]], dtype=torch.long)\n",
    "\n",
    "    edge_to_id = {frozenset((u, v)): i for (i, (u, v, _)) in enumerate(edges)}\n",
    "    types = torch.tensor([t for u,v,t in edges], dtype=torch.long).to(device)\n",
    "\n",
    "    x = x_init.to(device)\n",
    "\n",
    "    episode_loss = 0.0\n",
    "    episode_reward = 0.0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Construire edge_attr sous forme one-hot\n",
    "        edge_attr = F.one_hot(types, num_classes=2).to(torch.float)\n",
    "\n",
    "        # Forward\n",
    "        logits = model(x, edge_index.to(device), edge_attr)\n",
    "\n",
    "        # Masque arêtes de type 0\n",
    "        mask0 = (types == 0).to(device)\n",
    "        if mask0.sum() == 0:\n",
    "            break  # plus d'arêtes à flipper\n",
    "\n",
    "        logits0 = logits[mask0]\n",
    "        probs0 = F.softmax(logits0, dim=0)\n",
    "        dist = Categorical(probs0)\n",
    "\n",
    "        # Échantillonnage de l’action\n",
    "        a_idx = dist.sample()  # indice dans les arêtes type0\n",
    "        logp = dist.log_prob(a_idx)\n",
    "\n",
    "        # Traduire en index global\n",
    "        global_idx = mask0.nonzero()[a_idx]\n",
    "\n",
    "        # Exécuter l’action : flip\n",
    "        (r, (u2, v2)) = helper.recompense(global_idx)  # récompense\n",
    "\n",
    "        # Mise à jour temporaire de l’état\n",
    "        types[global_idx] = 1\n",
    "        idx2 = edge_to_id[frozenset((u2, v2))]\n",
    "        types[idx2] = 0\n",
    "\n",
    "        # Accumuler perte et récompense\n",
    "        episode_loss += -logp * r\n",
    "        episode_reward += r\n",
    "\n",
    "    # Backprop et mise à jour des paramètres\n",
    "    optimizer.zero_grad()\n",
    "    episode_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (ep+1) % 50 == 0:\n",
    "        print(f\"Épisode {ep+1:03d} | Réward cumulé {episode_reward:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e51af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} {} {} 0 0.022756126188708172 0.0\n",
      "{} {} {} 1000 0.02840931481140753 0.02327606146376715\n",
      "{} {} {} 2000 0.028099701280753286 0.023290077978213156\n",
      "{} {} {} 3000 0.027623065832404467 0.022913804059294187\n",
      "{} {} {} 4000 0.027414959853078725 0.022609507645399752\n",
      "{} {} {} 5000 0.027456345160827244 0.02247633190502447\n",
      "{} {} {} 6000 0.0272787943810083 0.02275852497857895\n",
      "{} {} {} 7000 0.027327515278350673 0.022518443154503163\n",
      "{} {} {} 8000 0.02750946933878812 0.022708161131770297\n",
      "{} {} {} 9000 0.027501757839369822 0.02290745087437691\n",
      "{} {} {} 10000 0.02746301248709971 0.02279403010790347\n",
      "{} {} {} 11000 0.027493653370804314 0.022888393899553168\n",
      "{} {} {} 12000 0.027471638445589728 0.023043204352965647\n",
      "{} {} {} 13000 0.02744095520159982 0.023056555133469363\n",
      "{} {} {} 14000 0.02751188670125636 0.023124670775328995\n",
      "{} {} {} 15000 0.02741742952248422 0.02306087774956102\n",
      "{} {} {} 16000 0.027487713219041154 0.022861480816149075\n",
      "{} {} {} 17000 0.0275956790946026 0.02283170821004826\n",
      "{} {} {} 18000 0.027737459077073194 0.022714652158887027\n",
      "{} {} {} 19000 0.027689872323373818 0.02274929593234699\n",
      "{} {} {} 20000 0.027800193600255783 0.022724463003659337\n",
      "{} {} {} 21000 0.02784207531306152 0.02266264388991565\n",
      "{} {} {} 22000 0.02783504664787685 0.022689569496586178\n",
      "{} {} {} 23000 0.027796663361426423 0.022613653735310178\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "rm = 0.0\n",
    "rr = 0.0\n",
    "rc = 0\n",
    "for iter_id in range(50000):\n",
    "    helper.reset(iter_id)\n",
    "    edges = helper.get_dataset()\n",
    "    types = torch.tensor([t for u,v,t in edges], dtype=torch.long).to(device)\n",
    "\n",
    "    edge_index = torch.tensor([[u for u,v,t in edges],\n",
    "                           [v for u,v,t in edges]], dtype=torch.long)\n",
    "\n",
    "    edge_to_id = {frozenset((u, v)): i for (i, (u, v, _)) in enumerate(edges)}\n",
    "\n",
    "    x = x_init.to(device)\n",
    "\n",
    "    episode_loss = 0.0\n",
    "    episode_reward = 0.0\n",
    "\n",
    "    # Construire edge_attr sous forme one-hot\n",
    "    edge_attr = F.one_hot(types, num_classes=2).to(torch.float)\n",
    "\n",
    "    # Forward\n",
    "    logits = model(x, edge_index.to(device), edge_attr)\n",
    "\n",
    "    # Masque arêtes de type 0\n",
    "    mask0 = (types == 0).to(device)\n",
    "    if mask0.sum() == 0:\n",
    "        break  # plus d'arêtes à flipper\n",
    "\n",
    "    logits0 = logits[mask0]\n",
    "    probs0 = F.softmax(logits0, dim=0)\n",
    "    dist = Categorical(probs0)\n",
    "\n",
    "    # Échantillonnage de l’action\n",
    "    a_idx = dist.sample()  # indice dans les arêtes type0\n",
    "    logp = dist.log_prob(a_idx)\n",
    "\n",
    "    # Traduire en index global\n",
    "    global_idx = mask0.nonzero()[a_idx]\n",
    "\n",
    "    global_idx2 = mask0.nonzero()[random.randrange(0, mask0.sum())]\n",
    "\n",
    "\n",
    "    # Exécuter l’action : flip\n",
    "    (r, (u2, v2)) = helper.recompense(global_idx)  # récompense\n",
    "\n",
    "    helper.reset(0)\n",
    "    (r2, (u2, v2)) = helper.recompense(global_idx2)  # récompense\n",
    "\n",
    "    rm += r\n",
    "    rr += r2\n",
    "    rc += 1\n",
    "    if iter_id % 1000 == 0.0:\n",
    "        print(\"{} {} {}\", iter_id, rm/rc, rr/rc)\n",
    "\n",
    "print(rm / rc, rr / rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23433bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71486dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
